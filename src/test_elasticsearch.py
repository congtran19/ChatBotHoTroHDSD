"""
Test file Ä‘á»ƒ thá»­ nghiá»‡m táº¥t cáº£ cÃ¡c hÃ m trong ElasticsearchVectorStore

CÃ¡c bÆ°á»›c test:
1. Khá»Ÿi táº¡o vector store
2. Load vÃ  embed tÃ i liá»‡u 
3. Test add() - thÃªm embeddings
4. Test count() - Ä‘áº¿m sá»‘ documents
5. Test search_by_knn() - tÃ¬m kiáº¿m vector
6. Test search_by_BM25() - tÃ¬m kiáº¿m text
7. Test search_hybrid() - tÃ¬m kiáº¿m káº¿t há»£p
8. Test get_by_id() - láº¥y document theo ID
9. Test delete() - xÃ³a documents
10. Test clear() - xÃ³a toÃ n bá»™
"""

from step1_loader import DocumentLoader
from step2_preprocessing import TextPreprocessor
from step4_chungking import MarkdownChunker
from step5_embedding import VietnameseEmbedder
from step6_vector_database import ElasticsearchVectorStore


def test_elasticsearch_vector_store():
    """Test Ä‘áº§y Ä‘á»§ cÃ¡c hÃ m cá»§a ElasticsearchVectorStore"""
    
    print("="*80)
    print("ğŸ§ª Báº®T Äáº¦U TEST ELASTICSEARCH VECTOR STORE")
    print("="*80)
    
    # ============ BÆ¯á»šC 1: Khá»Ÿi táº¡o cÃ¡c components ============
    print("\nğŸ“¦ BÆ¯á»šC 1: Khá»Ÿi táº¡o cÃ¡c components...")
    loader = DocumentLoader()
    preprocessor = TextPreprocessor()
    chunker = MarkdownChunker(chunk_size=500, chunk_overlap=50)
    embedder = VietnameseEmbedder()
    vector_db = ElasticsearchVectorStore(
        host="localhost",
        port=9200,
        index_name="rag_test_vectors",
        embedding_dim=768
    )
    print("âœ“ ÄÃ£ khá»Ÿi táº¡o táº¥t cáº£ components")
    
    # # ============ BÆ¯á»šC 2: Load vÃ  xá»­ lÃ½ document ============
    # print("\nğŸ“„ BÆ¯á»šC 2: Load vÃ  xá»­ lÃ½ document...")
    # file_path = "/home/congtran/Thá»±c HÃ nh RAG/data/documents/tai_lieu_huong_dan_cho_tct.pdf"
    
    # try:
    #     doc = loader.load(file_path)
    #     print(f"âœ“ Loaded: {doc.metadata.get('file_name')}")
    #     print(f"  - Pages: {doc.metadata.get('total_pages')}")
    #     # Preprocess
    #     doc.content = preprocessor.preprocess(doc.content)
    #     print("âœ“ Preprocessed document")
        
    #     # Chunk
    #     chunks = chunker.chunk_document(doc)
    #     print(f"âœ“ Created {len(chunks)} chunks")
        
    #     # Embed
    #     embeddings = embedder.embed(chunks)
    #     print(f"âœ“ Created {len(embeddings)} embeddings")
        
    # except FileNotFoundError as e:
    #     print(f"âŒ Lá»—i: File khÃ´ng tá»“n táº¡i - {e}")
    #     return
    # except Exception as e:
    #     print(f"âŒ Lá»—i khÃ´ng xÃ¡c Ä‘á»‹nh: {e}")
    #     return
    
    # # ============ BÆ¯á»šC 3: TEST add() - ThÃªm embeddings ============
    # print("\nâ• BÆ¯á»šC 3: TEST add() - ThÃªm embeddings vÃ o Elasticsearch...")
    # try:
    #     # Clear trÆ°á»›c Ä‘á»ƒ Ä‘áº£m báº£o database sáº¡ch
    #     vector_db.clear()
    #     print("âœ“ ÄÃ£ clear database trÆ°á»›c khi test")
        
    #     ids = vector_db.add(embeddings)
    #     print(f"âœ“ ÄÃ£ thÃªm {len(ids)} documents")
    #     print(f"  - Sample IDs: {ids[:]}")
    # except Exception as e:
    #     print(f"âŒ Lá»—i khi add: {e}")
    #     return
    
    # # ============ BÆ¯á»šC 4: TEST count() - Äáº¿m documents ============
    # print("\nğŸ”¢ BÆ¯á»šC 4: TEST count() - Äáº¿m sá»‘ documents...")
    # try:
    #     count = vector_db.count()
    #     print(f"âœ“ Tá»•ng sá»‘ documents trong index: {count}")
    # except Exception as e:
    #     print(f"âŒ Lá»—i khi count: {e}")
    
    # ============ BÆ¯á»šC 5: TEST search_by_knn() - Vector Search ============
    print("\nğŸ” BÆ¯á»šC 5: TEST search_by_knn() - TÃ¬m kiáº¿m báº±ng vector...")
    test_query = "LÃ m tháº¿ nÃ o Ä‘á»ƒ Ä‘á»•i máº­t kháº©u?"
    print(f"  Query: '{test_query}'")
    
    try:
        # Embed query
        query_embedding = embedder.embed_query(test_query)
        query_embedding = query_embedding.tolist() if hasattr(query_embedding, 'tolist') else query_embedding
        # Search
        knn_results = vector_db.search_by_knn(query_embedding, top_k=3)
        print(f"âœ“ TÃ¬m tháº¥y {len(knn_results)} káº¿t quáº£")
        
        for i, result in enumerate(knn_results, 1):
            print(f"\n  [{i}] Score: {result.score:.4f}")
            print(f"      Chunk ID: {result.chunk_id}")
            print(f"      Content preview: {result.content[:150]}...")
            print(f"      Metadata: {result.metadata}")
    except Exception as e:
        print(f"âŒ Lá»—i khi search_by_knn: {e}")
    
    # # ============ BÆ¯á»šC 6: TEST search_by_BM25() - Text Search ============
    # print("\nğŸ“ BÆ¯á»šC 6: TEST search_by_BM25() - TÃ¬m kiáº¿m báº±ng text...")
    # print(f"  Query: '{test_query}'")
    
    # try:
    #     bm25_results = vector_db.search_by_BM25(test_query, top_k=3)
    #     print(f"âœ“ TÃ¬m tháº¥y {len(bm25_results)} káº¿t quáº£")
        
    #     for i, result in enumerate(bm25_results, 1):
    #         print(f"\n  [{i}] Score: {result.score:.4f}")
    #         print(f"      Chunk ID: {result.chunk_id}")
    #         print(f"      Content preview: {result.content[:150]}...")
    #         print(f"      Metadata: {result.metadata}")
    # except Exception as e:
    #     print(f"âŒ Lá»—i khi search_by_BM25: {e}")
    
    # # ============ BÆ¯á»šC 7: TEST search_hybrid() - Hybrid Search ============
    # print("\nğŸ”€ BÆ¯á»šC 7: TEST search_hybrid() - TÃ¬m kiáº¿m káº¿t há»£p (Hybrid)...")
    # print(f"  Query: '{test_query}'")
    
    # try:
    #     # Test vá»›i nhiá»u vector_weight khÃ¡c nhau
    #     for vector_weight in [0.5]:
    #         print(f"\n  âš–ï¸  Vector weight: {vector_weight}, Text weight: {1-vector_weight}")
            
    #         hybrid_results = vector_db.search_hybrid(
    #             query=test_query,
    #             query_embedding=query_embedding,
    #             top_k=3,
    #             vector_weight=vector_weight
    #         )
            
    #         print(f"  âœ“ TÃ¬m tháº¥y {len(hybrid_results)} káº¿t quáº£:")
    #         for i, result in enumerate(hybrid_results, 1):
    #             print(f"\n    [{i}] Combined Score: {result.score:.4f}")
    #             print(f"        - kNN Score: {result.knn_score:.4f}")
    #             print(f"        - BM25 Score: {result.bm25_score:.4f}")
    #             print(f"        - Chunk ID: {result.chunk_id}")
    #             print(f"        - Content: {result.content[:100]}...")
    #             print(f"        - Metadata: {result.metadata}")
    # except Exception as e:
    #     print(f"âŒ Lá»—i khi search_hybrid: {e}")
    
    # # ============ BÆ¯á»šC 8: TEST get_by_id() - Láº¥y document theo ID ============
    # print("\nğŸ†” BÆ¯á»šC 8: TEST get_by_id() - Láº¥y document theo ID...")
    # try:
    #     if ids:
    #         test_id = ids[0]
    #         print(f"  Äang láº¥y document vá»›i ID: {test_id}")
            
    #         doc_result = vector_db.get_by_id(test_id)
    #         print(f"âœ“ ÄÃ£ láº¥y Ä‘Æ°á»£c document")
    #         print(f"  - Chunk ID: {doc_result.chunk_id}")
    #         print(f"  - Content preview: {doc_result.content[:150]}...")
    #         print(f"  - Metadata: {doc_result.metadata}")
    # except Exception as e:
    #     print(f"âŒ Lá»—i khi get_by_id: {e}")
    
    # # ============ BÆ¯á»šC 9: TEST delete() - XÃ³a documents ============
    # print("\nğŸ—‘ï¸  BÆ¯á»šC 9: TEST delete() - XÃ³a documents theo ID...")
    # try:
    #     # Äáº¿m trÆ°á»›c khi xÃ³a
    #     count_before = vector_db.count()
    #     print(f"  Sá»‘ documents trÆ°á»›c khi xÃ³a: {count_before}")
        
    #     # XÃ³a 2 documents Ä‘áº§u tiÃªn
    #     ids_to_delete = ids[:2]
    #     print(f"  Äang xÃ³a {len(ids_to_delete)} documents...")
        
    #     success = vector_db.delete(ids_to_delete)
    #     print(f"âœ“ XÃ³a thÃ nh cÃ´ng: {success}")
        
    #     # Äáº¿m sau khi xÃ³a
    #     count_after = vector_db.count()
    #     print(f"  Sá»‘ documents sau khi xÃ³a: {count_after}")
    #     print(f"  ÄÃ£ xÃ³a: {count_before - count_after} documents")
    # except Exception as e:
    #     print(f"âŒ Lá»—i khi delete: {e}")
    
    # # ============ BÆ¯á»šC 10: TEST clear() - XÃ³a toÃ n bá»™ ============
    # print("\nğŸ§¹ BÆ¯á»šC 10: TEST clear() - XÃ³a toÃ n bá»™ database...")
    # try:
    #     count_before_clear = vector_db.count()
    #     print(f"  Sá»‘ documents trÆ°á»›c khi clear: {count_before_clear}")
        
    #     success = vector_db.clear()
    #     print(f"âœ“ Clear thÃ nh cÃ´ng: {success}")
        
    #     count_after_clear = vector_db.count()
    #     print(f"  Sá»‘ documents sau khi clear: {count_after_clear}")
    # except Exception as e:
    #     print(f"âŒ Lá»—i khi clear: {e}")
    
#    ============ Káº¾T THÃšC TEST ============
    print("\n" + "="*80)
    print("âœ… ÄÃƒ HOÃ€N THÃ€NH Táº¤T Cáº¢ CÃC TEST")
    print("="*80)


if __name__ == "__main__":
    test_elasticsearch_vector_store()
